import streamlit as st
import json
import re
from typing import List, Dict

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="è‹±èªå­¦ç¿’ã‚¢ãƒ—ãƒª - æ–‡æ³•ãƒ»èªå½™è§£æ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–é–¢æ•°
def init_session_state():
    if 'sentences' not in st.session_state:
        st.session_state.sentences = []
    if 'current_index' not in st.session_state:
        st.session_state.current_index = 0
    if 'show_all' not in st.session_state:
        st.session_state.show_all = False
    if 'edit_mode' not in st.session_state:
        st.session_state.edit_mode = False
    if 'grammar_filter' not in st.session_state:
        st.session_state.grammar_filter = []
    if 'file_loaded' not in st.session_state:
        st.session_state.file_loaded = False

# åˆæœŸåŒ–ã‚’å®Ÿè¡Œ
init_session_state()

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .sentence-card {
        background-color: white;
        padding: 25px;
        margin-bottom: 20px;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .sentence-number {
        background-color: #e74c3c;
        color: white;
        padding: 5px 12px;
        border-radius: 20px;
        display: inline-block;
        margin-bottom: 15px;
        font-weight: bold;
    }
    .english-text {
        font-size: 20px;
        color: #2c3e50;
        margin-bottom: 15px;
        line-height: 1.6;
        font-weight: 500;
    }
    .japanese-text {
        font-size: 16px;
        color: #555;
        margin-bottom: 15px;
        padding: 15px;
        background-color: #f8f9fa;
        border-left: 4px solid #3498db;
        border-radius: 4px;
    }
    .grammar-points {
        background-color: #e8f4f8;
        padding: 15px;
        border-radius: 5px;
        margin-top: 15px;
    }
    .grammar-title {
        font-weight: bold;
        color: #2c3e50;
        margin-bottom: 8px;
    }
    .highlight {
        background-color: #fff3cd;
        padding: 2px 4px;
        border-radius: 3px;
    }
</style>
""", unsafe_allow_html=True)

# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
def go_prev():
    if st.session_state.current_index > 0:
        st.session_state.current_index -= 1

def go_next():
    if st.session_state.current_index < len(st.session_state.sentences) - 1:
        st.session_state.current_index += 1

def toggle_show_all():
    st.session_state.show_all = not st.session_state.show_all

def toggle_edit_mode():
    st.session_state.edit_mode = not st.session_state.edit_mode

def save_edit(index):
    japanese_key = f"japanese_{index}"
    grammar_key = f"grammar_{index}"
    
    if japanese_key in st.session_state:
        st.session_state.sentences[index]['japanese'] = st.session_state[japanese_key]
    if grammar_key in st.session_state:
        st.session_state.sentences[index]['grammar'] = st.session_state[grammar_key]

# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
def parse_tsv_content(content: str) -> List[Dict[str, str]]:
    """TSVãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’è§£æ"""
    sentences = []
    lines = content.strip().split('\n')
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
    start_index = 0
    if lines and lines[0].strip():
        first_line = lines[0].lower()
        # æœ€åˆã®ã‚¿ãƒ–åŒºåˆ‡ã‚Šã®è¦ç´ ã‚’ãƒã‚§ãƒƒã‚¯
        parts = lines[0].split('\t')
        if len(parts) >= 4:  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ + 3ã¤ã®ã‚«ãƒ©ãƒ 
            # 2ç•ªç›®ã®è¦ç´ ãŒã€Œè‹±æ–‡ã€ã¨ã„ã†ãƒ˜ãƒƒãƒ€ãƒ¼ã‹ãƒã‚§ãƒƒã‚¯
            if parts[1].strip() == 'è‹±æ–‡':
                start_index = 1
        elif 'english' in first_line or 'japanese' in first_line or 'grammar' in first_line:
            start_index = 1
    
    for i in range(start_index, len(lines)):
        line = lines[i]
        if line.strip():
            parts = line.split('\t')
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç•ªå·ãŒã‚ã‚‹å ´åˆã¯ã€2ç•ªç›®ã®è¦ç´ ã‹ã‚‰å–å¾—
            if len(parts) >= 4 and parts[0].strip().isdigit():
                sentence = {
                    'english': parts[1].strip() if parts[1] else '',
                    'japanese': parts[2].strip() if len(parts) > 2 and parts[2] else '',
                    'grammar': parts[3].strip() if len(parts) > 3 and parts[3] else ''
                }
            elif len(parts) >= 3:
                sentence = {
                    'english': parts[0].strip() if parts[0] else '',
                    'japanese': parts[1].strip() if len(parts) > 1 and parts[1] else '',
                    'grammar': parts[2].strip() if len(parts) > 2 and parts[2] else ''
                }
            else:
                continue
            
            # ç©ºã®è‹±æ–‡ã¯ã‚¹ã‚­ãƒƒãƒ—
            if sentence['english'] and sentence['english'] not in ['è‹±æ–‡', 'english']:
                sentences.append(sentence)
    
    return sentences

def parse_json_content(content: str) -> List[Dict[str, str]]:
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’è§£æ"""
    try:
        data = json.loads(content)
        
        if isinstance(data, list):
            sentences = []
            for item in data:
                if isinstance(item, dict):
                    sentence = {
                        'english': str(item.get('english', item.get('text', item.get('sentence', '')))),
                        'japanese': str(item.get('japanese', item.get('translation', ''))),
                        'grammar': str(item.get('grammar', item.get('grammar_points', '')))
                    }
                    sentences.append(sentence)
            return sentences
        elif isinstance(data, dict) and 'sentences' in data:
            return parse_json_content(json.dumps(data['sentences']))
    except:
        pass
    return []

def parse_pipe_text(content: str) -> List[Dict[str, str]]:
    """ãƒ‘ã‚¤ãƒ—åŒºåˆ‡ã‚Šãƒ†ã‚­ã‚¹ãƒˆã‚’è§£æ"""
    sentences = []
    lines = content.strip().split('\n')
    
    for line in lines:
        line = line.strip()
        if line and 'ï½œ' in line:
            line = re.sub(r'^\d+[.ã€]\s*', '', line)
            parts = line.split('ï½œ')
            if len(parts) >= 1:
                sentence = {
                    'english': parts[0].strip(),
                    'japanese': parts[1].strip() if len(parts) > 1 else '',
                    'grammar': parts[2].strip() if len(parts) > 2 else ''
                }
                sentences.append(sentence)
    
    return sentences

def parse_plain_text(content: str) -> List[Dict[str, str]]:
    """ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è§£æ"""
    sentences = []
    lines = content.strip().split('\n')
    
    for line in lines:
        line = line.strip()
        if line:
            sentence = {
                'english': line,
                'japanese': '',
                'grammar': ''
            }
            sentences.append(sentence)
    
    return sentences

def highlight_grammar_points(text: str) -> str:
    """æ–‡æ³•ãƒã‚¤ãƒ³ãƒˆã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆ"""
    # æ¥ç¶šè©
    conjunctions = ['However', 'Therefore', 'Although', 'Because', 'Since', 'While', 'When', 'If', 'Unless', 'As']
    for conj in conjunctions:
        text = text.replace(conj, f'<span class="highlight">{conj}</span>')
    
    # é–¢ä¿‚è©
    relatives = ['which', 'who', 'whom', 'whose', 'that', 'where', 'when']
    for rel in relatives:
        pattern = r'\b' + rel + r'\b'
        text = re.sub(pattern, f'<span class="highlight">{rel}</span>', text, flags=re.IGNORECASE)
    
    return text

def extract_grammar_categories(sentences: List[Dict[str, str]]) -> List[str]:
    """æ–‡æ³•ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’æŠ½å‡º"""
    categories = set()
    grammar_patterns = {
        'ç¾åœ¨å®Œäº†å½¢': r'ç¾åœ¨å®Œäº†|have\s+\w+ed|has\s+\w+ed',
        'éå»å®Œäº†å½¢': r'éå»å®Œäº†|had\s+\w+ed',
        'é–¢ä¿‚è©': r'é–¢ä¿‚[ä»£å]?è©|which|who|whom|whose|thatç¯€',
        'ä»®å®šæ³•': r'ä»®å®šæ³•|would\s+have|could\s+have|should\s+have',
        'å—å‹•æ…‹': r'å—[å‹•èº«]æ…‹|be\s+\w+ed|was\s+\w+ed|were\s+\w+ed',
        'ä¸å®šè©': r'ä¸å®šè©|to\s+\w+',
        'å‹•åè©': r'å‹•åè©|ingå½¢',
        'åˆ†è©æ§‹æ–‡': r'åˆ†è©æ§‹æ–‡|ing\s*å¥',
        'æ¯”è¼ƒç´š': r'æ¯”è¼ƒç´š|more\s+\w+|er\s+than',
        'æœ€ä¸Šç´š': r'æœ€ä¸Šç´š|most\s+\w+|est'
    }
    
    for sentence in sentences:
        grammar_text = sentence.get('grammar', '')
        for category, pattern in grammar_patterns.items():
            if re.search(pattern, grammar_text, re.IGNORECASE):
                categories.add(category)
    
    return sorted(list(categories))

def display_sentence(index: int, sentence: Dict[str, str]):
    """æ–‡ã‚’è¡¨ç¤º"""
    with st.container():
        st.markdown(f'<div class="sentence-card">', unsafe_allow_html=True)
        st.markdown(f'<span class="sentence-number">æ–‡ {index + 1}</span>', unsafe_allow_html=True)
        
        # è‹±æ–‡
        english_highlighted = highlight_grammar_points(sentence['english'])
        st.markdown(f'<div class="english-text">{english_highlighted}</div>', unsafe_allow_html=True)
        
        if st.session_state.edit_mode:
            # ç·¨é›†ãƒ¢ãƒ¼ãƒ‰
            col1, col2 = st.columns(2)
            with col1:
                new_japanese = st.text_area(
                    "æ—¥æœ¬èªè¨³",
                    value=sentence['japanese'],
                    key=f"japanese_{index}",
                    height=100
                )
            with col2:
                new_grammar = st.text_area(
                    "æ–‡æ³•ãƒ»èªå½™",
                    value=sentence['grammar'],
                    key=f"grammar_{index}",
                    height=100
                )
            
            if st.button("ğŸ’¾ ä¿å­˜", key=f"save_{index}", on_click=save_edit, args=(index,)):
                st.success("ä¿å­˜ã—ã¾ã—ãŸ")
        else:
            # è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰
            if sentence['japanese']:
                st.markdown(f'<div class="japanese-text">{sentence["japanese"]}</div>', unsafe_allow_html=True)
            
            if sentence['grammar']:
                st.markdown('<div class="grammar-points">', unsafe_allow_html=True)
                st.markdown('<div class="grammar-title">ğŸ“š æ–‡æ³•ãƒ»èªå½™ã®ãƒã‚¤ãƒ³ãƒˆ</div>', unsafe_allow_html=True)
                st.markdown(f'<div class="grammar-content">{sentence["grammar"]}</div>', unsafe_allow_html=True)
                st.markdown('</div>', unsafe_allow_html=True)
        
        st.markdown('</div>', unsafe_allow_html=True)

# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª
def main():
    st.title("ğŸ“ è‹±èªå­¦ç¿’ã‚¢ãƒ—ãƒª - æ–‡æ³•ãƒ»èªå½™è§£æ")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("è¨­å®š")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        st.subheader("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿")
        uploaded_file = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
            type=['tsv', 'json', 'txt'],
            help="TSVã€JSONã€ã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            key="file_uploader"
        )
        
        if uploaded_file is not None and not st.session_state.file_loaded:
            content = uploaded_file.read().decode('utf-8')
            
            if uploaded_file.name.endswith('.tsv'):
                sentences = parse_tsv_content(content)
            elif uploaded_file.name.endswith('.json'):
                sentences = parse_json_content(content)
            elif 'ï½œ' in content:
                sentences = parse_pipe_text(content)
            else:
                sentences = parse_plain_text(content)
            
            if sentences:
                st.session_state.sentences = sentences
                st.session_state.current_index = 0
                st.session_state.file_loaded = True
                st.success(f"{len(sentences)}å€‹ã®æ–‡ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                st.rerun()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„çŠ¶æ…‹ã«æˆ»ã£ãŸå ´åˆã®å‡¦ç†
        if uploaded_file is None and st.session_state.file_loaded:
            st.session_state.file_loaded = False
            st.session_state.sentences = []
            st.session_state.current_index = 0
            st.rerun()
        
        st.divider()
        
        # æ–‡æ³•ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if st.session_state.sentences:
            st.subheader("ğŸ” æ–‡æ³•ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
            categories = extract_grammar_categories(st.session_state.sentences)
            selected_categories = st.multiselect(
                "æ–‡æ³•é …ç›®ã‚’é¸æŠ",
                categories,
                default=st.session_state.grammar_filter,
                key="grammar_filter_select"
            )
            st.session_state.grammar_filter = selected_categories
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    if not st.session_state.sentences:
        st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        return
    
    # çµ±è¨ˆæƒ…å ±
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ç·æ–‡æ•°", len(st.session_state.sentences))
    with col2:
        current = st.session_state.current_index + 1
        st.metric("ç¾åœ¨ã®æ–‡", f"{current}/{len(st.session_state.sentences)}")
    with col3:
        incomplete = sum(1 for s in st.session_state.sentences if not s['japanese'] or not s['grammar'])
        st.metric("æœªå®Œæˆ", incomplete)
    with col4:
        if st.session_state.grammar_filter:
            filtered = len([s for s in st.session_state.sentences 
                          if any(cat in s.get('grammar', '') for cat in st.session_state.grammar_filter)])
            st.metric("ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼çµæœ", filtered)
    
    st.divider()
    
    # ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒœã‚¿ãƒ³
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.button(
            "â¬…ï¸ å‰ã¸", 
            disabled=st.session_state.current_index <= 0,
            on_click=go_prev,
            key="prev_button"
        )
    
    with col2:
        st.button(
            "â¡ï¸ æ¬¡ã¸", 
            disabled=st.session_state.current_index >= len(st.session_state.sentences) - 1,
            on_click=go_next,
            key="next_button"
        )
    
    with col3:
        toggle_text = "ğŸ”„ å…¨æ–‡è¡¨ç¤º" if not st.session_state.show_all else "ğŸ“„ å˜æ–‡è¡¨ç¤º"
        st.button(
            toggle_text,
            on_click=toggle_show_all,
            key="toggle_button"
        )
    
    with col4:
        edit_text = "âœï¸ ç·¨é›†ãƒ¢ãƒ¼ãƒ‰" if not st.session_state.edit_mode else "ğŸ‘ï¸ è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰"
        st.button(
            edit_text,
            on_click=toggle_edit_mode,
            key="edit_button"
        )
    
    st.divider()
    
    # æ–‡ã®è¡¨ç¤º
    if st.session_state.show_all:
        # å…¨æ–‡è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰
        for i, sentence in enumerate(st.session_state.sentences):
            if st.session_state.grammar_filter:
                if not any(cat in sentence.get('grammar', '') for cat in st.session_state.grammar_filter):
                    continue
            
            display_sentence(i, sentence)
    else:
        # å˜æ–‡è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰
        if 0 <= st.session_state.current_index < len(st.session_state.sentences):
            sentence = st.session_state.sentences[st.session_state.current_index]
            display_sentence(st.session_state.current_index, sentence)
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆé–‹ç™ºä¸­ã®ã¿è¡¨ç¤ºï¼‰
    with st.expander("ãƒ‡ãƒãƒƒã‚°æƒ…å ±", expanded=False):
        st.write("ç¾åœ¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹:", st.session_state.current_index)
        st.write("ç·æ–‡æ•°:", len(st.session_state.sentences))
        st.write("ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æ¸ˆã¿:", st.session_state.file_loaded)

if __name__ == "__main__":
    main()